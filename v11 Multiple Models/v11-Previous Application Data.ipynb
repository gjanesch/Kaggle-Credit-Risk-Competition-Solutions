{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> This notebook is used for processing the data in the supplemental <TT>previous_application</TT> file. </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import v11_common as com\n",
    "\n",
    "import feather\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pending changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREV_APP_FILE = com.DATA_FILE_FOLDER + \"previous_application.feather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app = pd.read_feather(PREV_APP_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>There are a few columns that have entries reading \"XNA\", and several date-related columns with values of 365243; these are both to be treated as NA values.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xna_cols = [\"NAME_PAYMENT_TYPE\",\"NAME_CLIENT_TYPE\", \"NAME_CONTRACT_TYPE\"]\n",
    "for col in xna_cols:\n",
    "    prev_app[col] = prev_app[col].astype(\"str\").replace(\"XNA\",np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_365243 = [\"DAYS_FIRST_DRAWING\",\"DAYS_FIRST_DUE\",\"DAYS_LAST_DUE_1ST_VERSION\",\n",
    "                    \"DAYS_LAST_DUE\",\"DAYS_TERMINATION\"]\n",
    "prev_app[cols_with_365243] = prev_app[cols_with_365243].replace(365243, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app[\"AMT_CREDIT\"].fillna(value = prev_app[\"AMT_APPLICATION\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Some comparisons of the sizes of the monetary values in the data could be useful, so we'll engineer some of those.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_credit_diff = prev_app[\"AMT_APPLICATION\"] - prev_app[\"AMT_CREDIT\"]\n",
    "prev_app[\"APP_CREDIT_DIFF\"] = app_credit_diff\n",
    "app_credit_ratio = prev_app[\"AMT_APPLICATION\"] / prev_app[\"AMT_CREDIT\"]\n",
    "prev_app[\"APP_CREDIT_RATIO\"] = app_credit_ratio.replace([np.inf,-np.inf],np.nan)\n",
    "\n",
    "conditions = [app_credit_diff < 0, app_credit_diff == 0, app_credit_diff > 0]\n",
    "choices = [\"MORE_CREDIT_THAN_ASKED\",\"EQUAL_TO_CREDIT_ASKED\",\"LESS_CREDIT_THAN_ASKED\"]\n",
    "prev_app[\"RECEIVED_VS_APPLIED_CREDIT\"] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_gr = prev_app.groupby(\"SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greg/.local/lib/python3.6/site-packages/scipy/stats/stats.py:313: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n"
     ]
    }
   ],
   "source": [
    "# Aggregations & new columns\n",
    "prev_app_sub = prev_app_gr.agg({\"AMT_ANNUITY\":[min,max,np.mean,sum],\n",
    "                                \"AMT_CREDIT\":[max,min,np.mean,sum],\n",
    "                                \"AMT_APPLICATION\":[min,max,np.mean,sum,com.log_average],\n",
    "                                \"APP_CREDIT_DIFF\":[max,min],\n",
    "                                \"APP_CREDIT_RATIO\":[min,np.mean,max,com.geom_mean],\n",
    "                                \"DAYS_DECISION\":min,\n",
    "                                \"NFLAG_LAST_APPL_IN_DAY\":sum,\n",
    "                                \"AMT_DOWN_PAYMENT\":[min,max,np.mean],\n",
    "                                \"DAYS_TERMINATION\":[min,max]})\n",
    "prev_app_sub.columns = [\"MIN_AMT_ANNUITY\",\"MAX_AMT_ANNUITY\",\"AVG_AMT_ANNUITY\",\"TOTAL_AMT_ANNUITY\",\n",
    "                        \"MAX_CREDIT_RECEIVED\",\"MIN_CREDIT_RECEIVED\",\"AVG_CREDIT_RECEIVED\",\"TOTAL_CREDIT_RECEIVED\",\n",
    "                        \"MIN_AMT_APPLICATION\",\"MAX_AMT_APPLICATION\",\"AVG_AMT_APPLICATION\",\"TOTAL_AMT_APPLICATION\",\"LOG_AVG_AMT_APPLICATION\",\n",
    "                        \"MAX_APP_CREDIT_DIFF\", \"MIN_APP_CREDIT_DIFF\",\n",
    "                        \"MIN_APP_CREDIT_RATIO\",\"AMEAN_APP_CREDIT_RATIO\", \"MAX_APP_CREDIT_RATIO\",\"GMEAN_APP_CREDIT_RATIO\",\n",
    "                        \"LAST_DECISION_DATE\",\n",
    "                        \"NUM_APPS_IN_ON_LAST_DAY\",\n",
    "                        \"MIN_AMT_DOWN_PAYMENT\",\"MAX_AMT_DOWN_PAYMENT\",\"AVG_AMT_DOWN_PAYMENT\",\n",
    "                        \"OLDEST_TERMINATION_DATE\", \"NEWEST_TERMINATION_DATE\"]\n",
    "\n",
    "prev_app_sub[\"NUMBER_APPLICATIONS\"] = prev_app_gr.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_contract = com.count_frac_cols(prev_app_gr,\n",
    "                                        col = \"NAME_CONTRACT_STATUS\",\n",
    "                                        middle_string = \"CONTRACT_STATUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_client_type = com.count_frac_cols(prev_app_gr,\n",
    "                                           col = \"NAME_PAYMENT_TYPE\",\n",
    "                                           middle_string = \"PREV_PAYMENT_TYPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_amt_received = com.count_frac_cols(prev_app_gr,\n",
    "                                            col = \"RECEIVED_VS_APPLIED_CREDIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_contract_types = com.count_frac_cols(prev_app_gr,\n",
    "                                              col = \"NAME_CONTRACT_TYPE\",\n",
    "                                              middle_string = \"CONTRACT_TYPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_data = pd.concat([prev_app_sub, prev_app_contract, prev_app_amt_received,\n",
    "                           prev_app_contract_types, prev_app_client_type],\n",
    "                          axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Logistic regression predictions.  Several columns are stripped out due to multicollinearity issues (the threshold point for this is a correlation of greater than 0.75 between two variables).  A few other columns are transformed so that they have higher correlations with the TARGET variable (which seems to help the models along); since the ranking order of the points stays the same in these circumstances, the gradient boosting shouldn't be particularly affected. </h4>\n",
    "\n",
    "<h4> LAST AUC VALUE: 0.6194 </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Correlation Pairs:\n",
    "    \n",
    "NOT CHECKED YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load objects needed for logistic regression\n",
    "target_df = pd.read_feather(\"target.feather\")\n",
    "\n",
    "prev_app_poly = {\"NUM_CONTRACT_STATUS_Refused\":0.5, \"LAST_DECISION_DATE\":2}\n",
    "\n",
    "high_cor_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6184704044726084\n",
      "0.61597934003202\n",
      "0.6193075136664563\n",
      "0.6208053429426919\n",
      "0.6262680960960947\n",
      "0.6190420311177428\n",
      "0.6214467451844795\n",
      "0.6167316480972425\n",
      "Avg AUC: 0.6197563902011669\n"
     ]
    }
   ],
   "source": [
    "# Make logistic regression predictions\n",
    "test_aucs = []\n",
    "for _ in range(8):\n",
    "    pred, auc = com.log_regress_other_files(com.add_polynomial_terms(prev_app_data.reset_index().copy(), prev_app_poly),\n",
    "                                            target_df,\n",
    "                                            high_cor_columns)\n",
    "    test_aucs.append(auc)\n",
    "    print(auc)\n",
    "print(\"Avg AUC: \" + str(np.mean(test_aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_data[\"PREV_APP_LR_PREDS\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_data.reset_index().to_feather(\"previous_application_sub.feather\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
