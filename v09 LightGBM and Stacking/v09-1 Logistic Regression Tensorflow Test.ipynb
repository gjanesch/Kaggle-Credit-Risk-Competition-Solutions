{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greg/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import feather\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorflow_logistic_regression(train_data, target, test_df = None, training_epochs = 10, learning_rate = 0.005):\n",
    "    \"\"\"\n",
    "    Performs the tensorflow operations for training a basic logistic regression model on the specified\n",
    "    dataframe, and returns the model's predictions for the full data set.  It is intended to be used with\n",
    "    the supplemental files for Kaggle's Credit Risk competition, in order to generate some new features/\n",
    "    implement model stacking.\n",
    "    \"\"\"\n",
    "    ncol = train_data.shape[1]\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [None, ncol], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, [None, 1], name = \"Y\")\n",
    "    weights = tf.Variable(tf.zeros([ncol,1]))\n",
    "    bias = tf.Variable(tf.zeros([1]))\n",
    "    \n",
    "    pred = tf.sigmoid(tf.add(tf.matmul(X, weights), bias))\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = pred, labels = Y))\n",
    "    auc = tf.metrics.auc(labels = Y, predictions = pred, name = \"auc\")\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    init_loc = tf.local_variables_initializer()\n",
    "    auc_history = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        sess.run(init_loc)\n",
    "        \n",
    "        for epoch in range(training_epochs):\n",
    "            train_train, train_val, target_train, target_val = train_test_split(train_data,target)\n",
    "            \n",
    "            c,_ = sess.run([cost, optimizer], feed_dict = {X:train_train, Y: target_train})\n",
    "            predictions = sess.run(pred, feed_dict = {X:train_val, Y: target_val})\n",
    "            auc_history.append(sess.run(auc, feed_dict = {X:train_val, Y: target_val})[1])\n",
    "            \n",
    "        full_train_predictions = sess.run(pred, feed_dict = {X:train_data, Y:target})\n",
    "    \n",
    "    return full_train_predictions, auc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_regress_other_files(train_IDs, target, file_df):\n",
    "    file_df = file_df.loc[file_df[\"SK_ID_CURR\"].isin(train_IDs),:]\n",
    "    target = target[target[\"SK_ID_CURR\"].isin(file_df[\"SK_ID_CURR\"])][\"TARGET\"]\n",
    "    \n",
    "    file_data = file_df.drop(\"SK_ID_CURR\", axis = 1).values.astype(\"float32\")\n",
    "    target = target.values.reshape([len(target),1]).astype(\"float32\")\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    file_data = sc.fit_transform(file_data)\n",
    "    \n",
    "    predictions, auc_scores = tensorflow_logistic_regression(file_data, target)\n",
    "    \n",
    "    return predictions, auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_feather(\"./../Solution attempts/v09 train data.feather\")\n",
    "target = pd.read_feather(\"./../Solution attempts/v09 target.feather\")[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_fill = [\"TOTAL_CURRENT_CREDIT_AMT\", \"TOTAL_CURRENT_CREDIT_DEBT\", \"CREDIT_COUNT\", \"NUM_CREDIT_ACTIVE\",\n",
    "                \"NUMBER_APPROVED\", \"NUMBER_CANCELED\",\"NUMBER_REFUSED\", \"NUMBER_UNUSED\", \"NUMBER_APPLICATIONS\",\n",
    "                \"ANY_OVERDUE\", \"NUM_LATE_CC_PAYMENTS\",\"MAX_CREDIT_LIMIT\",\"NUM_PREV_CC_LOANS\",\"NUM_PAYMENTS_UNDER\",\n",
    "                \"NUM_PAYMENTS_LATE\",\"NUM_LATE_POS_PAYMENTS\", \"NUM_CREDIT_CLOSED\", \"MAX_DPD\", \"MAX_DRAWINGS_IN_MONTH\",\n",
    "                \"DAYS_EMPLOYED\", \"OBS_30_CNT_SOCIAL_CIRCLE\", \"DEF_30_CNT_SOCIAL_CIRCLE\", \"OBS_60_CNT_SOCIAL_CIRCLE\",\n",
    "                \"DEF_60_CNT_SOCIAL_CIRCLE\"]\n",
    "\n",
    "train[cols_to_fill] = train[cols_to_fill].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cols = train.apply(lambda x: sum(x.isnull()), axis = 0)\n",
    "full_cols = full_cols[full_cols < 3000].index.tolist()\n",
    "train = train[full_cols]\n",
    "train.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_indices = train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.values.astype('float32')\n",
    "target = target[kept_indices]\n",
    "target = target.values.reshape([len(target),1]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(target_val, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(target, full_train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_sub = pd.read_feather(\"bureau_sub.feather\")\n",
    "target = pd.read_feather(\"./../Solution attempts/v09 target.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions, auc_scores = log_regress_other_files(train[\"SK_ID_CURR\"], target, bureau_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5875257,\n",
       " 0.59931827,\n",
       " 0.6029048,\n",
       " 0.60504097,\n",
       " 0.6051328,\n",
       " 0.60614395,\n",
       " 0.6065419,\n",
       " 0.6076418,\n",
       " 0.6081058,\n",
       " 0.60809624]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
